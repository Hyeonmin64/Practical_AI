[How Do Transformers Learn Topic Structure: Towards a Mechanistic Understanding](https://arxiv.org/abs/2303.04245)

-
-

[Larger language models do in-context learning differently](https://arxiv.org/abs/2303.03846)

-
-

[STABILIZING TRANSFORMER TRAINING BY PREVENTING ATTENTION ENTROPY COLLAPSE](https://arxiv.org/pdf/2303.06296.pdf)

-
-

Question) in-context learning?

Answer) [How does in-context learning work? A framework for understanding the differences from traditional supervised learning](http://ai.stanford.edu/blog/understanding-incontext/)
